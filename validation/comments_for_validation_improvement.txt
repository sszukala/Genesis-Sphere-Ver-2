# Recommendations for improving the likelihood calculation in parameter_sweep_validation.py

## Current issues:
1. The current chi-squared calculations in calculate_h0_chi2, calculate_sne_chi2, and calculate_bao_chi2 
   are approximations that don't use the standard statistical definition of chi-squared.
2. The weighted combination of these values in log_likelihood is not statistically well-justified.

## Proper chi-squared calculation:
The correct approach is to calculate chi-squared as:
  χ² = ∑[(data_i - model_i)²/σ_i²]
where:
  - data_i is the observed value
  - model_i is the predicted value from your model
  - σ_i is the measurement uncertainty (standard deviation) for each data point

## Implementation with CuPy GPU Acceleration:
First, install CuPy with: `pip install cupy-cuda11x` (replace with your CUDA version)

### 0. GPU-accelerated imports and setup:
```python
# Try to import CuPy for GPU acceleration, fall back to NumPy if not available
try:
    import cupy as cp
    HAS_GPU = True
    print("CuPy successfully imported. Using GPU acceleration.")
except ImportError:
    import numpy as np
    cp = np  # Use NumPy as a fallback
    HAS_GPU = False
    print("CuPy not found. Using CPU with NumPy instead.")
    
def to_gpu(arr):
    """Transfer NumPy array to GPU if GPU is available"""
    if HAS_GPU and isinstance(arr, np.ndarray):
        return cp.asarray(arr)
    return arr
    
def to_cpu(arr):
    """Transfer CuPy array back to CPU if needed"""
    if HAS_GPU and isinstance(arr, cp.ndarray):
        return cp.asnumpy(arr)
    return arr
```

### 1. For H0 correlation:
```python
def calculate_h0_chi2(gs_model, h0_data):
    """Calculate proper chi-squared for H0 measurements with GPU acceleration"""
    # Get years and H0 values with uncertainties
    years = h0_data['year'].values
    h0_obs = h0_data['H0'].values
    h0_err = h0_data['H0_err'].values
    
    # Transfer to GPU if available
    years_gpu = to_gpu(years)
    h0_obs_gpu = to_gpu(h0_obs)
    h0_err_gpu = to_gpu(h0_err)
    
    # Get Genesis-Sphere predictions on GPU
    # Note: gs_predicted_h0_variations needs to be modified to use cp instead of np
    h0_pred_gpu = gs_predicted_h0_variations_gpu(gs_model, years_gpu)
    
    # Calculate chi-squared on GPU
    residuals_gpu = (h0_obs_gpu - h0_pred_gpu) / h0_err_gpu
    chi2 = float(cp.sum(residuals_gpu**2))  # Convert back to Python float
    
    return chi2
```

### 2. For supernovae:
```python
def calculate_sne_chi2(gs_model, sne_data):
    """Calculate proper chi-squared for supernovae distance modulus with GPU acceleration"""
    # Extract redshifts and distance moduli with uncertainties
    redshifts = sne_data['z'].values
    mu_obs = sne_data['mu'].values
    mu_err = sne_data['mu_err'].values
    
    # Transfer to GPU if available
    redshifts_gpu = to_gpu(redshifts)
    mu_obs_gpu = to_gpu(mu_obs)
    mu_err_gpu = to_gpu(mu_err)
    
    # Get predictions on GPU
    mu_pred_gpu = gs_predicted_distance_modulus_gpu(gs_model, redshifts_gpu)
    
    # Calculate chi-squared on GPU - much faster for large SNe datasets
    residuals_gpu = (mu_obs_gpu - mu_pred_gpu) / mu_err_gpu
    chi2 = float(cp.sum(residuals_gpu**2))
    
    return chi2
```

### 3. For BAO:
```python
def calculate_bao_chi2(gs_model, bao_data):
    """Calculate proper chi-squared for BAO measurements with GPU acceleration"""
    # Extract redshifts and sound horizon with uncertainties
    redshifts = bao_data['z'].values
    rd_obs = bao_data['rd'].values
    rd_err = bao_data['rd_err'].values
    
    # Transfer to GPU if available
    redshifts_gpu = to_gpu(redshifts)
    rd_obs_gpu = to_gpu(rd_obs)
    rd_err_gpu = to_gpu(rd_err)
    
    # Get predictions on GPU
    rd_pred_gpu = gs_predicted_bao_feature_gpu(gs_model, redshifts_gpu)
    
    # Calculate chi-squared on GPU
    residuals_gpu = (rd_obs_gpu - rd_pred_gpu) / rd_err_gpu
    chi2 = float(cp.sum(residuals_gpu**2))
    
    return chi2
```

### 4. In log_likelihood:
```python
# Simply sum these chi-squared values without weighting
total_chi2 = chi2_h0 + chi2_sne + chi2_bao
logL = -0.5 * total_chi2
```

### 5. Modifying the prediction functions to use GPU:

```python
# Example of a GPU-accelerated prediction function
def gs_predicted_h0_variations_gpu(gs_model, years_gpu):
    """GPU-accelerated version of the H0 prediction function"""
    # Get the base H0 value (typically around 70 km/s/Mpc)
    h0_base = 70.0
    
    # Get Genesis-Sphere parameters
    omega = gs_model.omega
    alpha = gs_model.alpha
    beta = gs_model.beta
    epsilon = gs_model.epsilon
    
    # Normalized time values (map years to model time)
    # The specific mapping depends on your model's time scale
    t = (years_gpu - 2000.0) / 100.0  # Example: center at year 2000
    
    # Calculate time-density and temporal flow on GPU
    sin_term = cp.sin(omega * t)
    rho = (1.0 / (1.0 + sin_term**2)) * (1.0 + alpha * t**2)
    tf = 1.0 / (1.0 + beta * (cp.abs(t) + epsilon))
    
    # Calculate H0 variations based on Genesis-Sphere model
    h0_pred = h0_base * (1.0 + 0.1 * cp.sin(omega * t)) * (1.0 + 0.05 * rho) / cp.sqrt(tf)
    
    return h0_pred
```

## Performance considerations:

1. **Data Transfer Overhead**: GPU acceleration is most beneficial for large datasets. For small datasets, the overhead of transferring data to/from the GPU might exceed the computational gains.

2. **Batch Processing**: If memory is limited, process the data in batches. For SNe data with thousands of points:
   ```python
   BATCH_SIZE = 1000
   n_batches = (len(redshifts) + BATCH_SIZE - 1) // BATCH_SIZE
   chi2 = 0.0
   
   for i in range(n_batches):
       start_idx = i * BATCH_SIZE
       end_idx = min((i + 1) * BATCH_SIZE, len(redshifts))
       batch_redshifts = to_gpu(redshifts[start_idx:end_idx])
       # ... similarly for other arrays
       # Calculate chi2 for this batch and add to total
   ```

3. **Memory Management**: Explicitly free GPU memory when no longer needed:
   ```python
   if HAS_GPU:
       # After calculations are done
       del some_large_gpu_array
       cp.get_default_memory_pool().free_all_blocks()
   ```

## Additional GPU Implementation Details:

### 6. Implementing GPU acceleration in the MCMC sampler:

When integrating GPU acceleration with the MCMC sampler, consider these approaches:

```python
# Option 1: GPU-accelerated version of log_posterior (recommended approach)
def log_posterior_gpu(params, data_h0, data_sne, data_bao, fixed_alpha, fixed_epsilon):
    """GPU-accelerated log posterior calculation"""
    # Check prior - no need to use GPU for this simple check
    lp = log_prior(params)
    if not np.isfinite(lp):
        return -np.inf
    
    # Calculate log likelihood using GPU acceleration
    ll = log_likelihood_gpu(params, data_h0, data_sne, data_bao, fixed_alpha, fixed_epsilon)
    
    return lp + ll
```

### 7. Modifying main() to use GPU acceleration:

```python
# In main() function, replace the sampler initialization:
if HAS_GPU:
    print("Using GPU-accelerated MCMC sampling")
    sampler = emcee.EnsembleSampler(
        nwalkers, ndim, log_posterior_gpu, 
        args=(h0_data, sne_data, bao_data, args.alpha, args.epsilon)
    )
else:
    print("Using CPU-based MCMC sampling")
    sampler = emcee.EnsembleSampler(
        nwalkers, ndim, log_posterior, 
        args=(h0_data, sne_data, bao_data, args.alpha, args.epsilon)
    )
```

### 8. Loading data directly to GPU for better performance:

For very large datasets, consider loading the data directly onto the GPU at the beginning:

```python
def load_data_to_gpu():
    """Load all datasets and transfer to GPU"""
    # Load data
    h0_data = load_h0_measurements()
    sne_data = load_supernovae_data()
    bao_data = load_bao_data()
    
    if HAS_GPU:
        # Create GPU versions of critical data arrays
        gpu_data = {
            'h0': {
                'year': to_gpu(h0_data['year'].values),
                'H0': to_gpu(h0_data['H0'].values),
                'H0_err': to_gpu(h0_data['H0_err'].values),
                'df': h0_data  # Keep original DataFrame for reference
            },
            'sne': {
                'z': to_gpu(sne_data['z'].values),
                'mu': to_gpu(sne_data['mu'].values),
                'mu_err': to_gpu(sne_data['mu_err'].values),
                'df': sne_data
            },
            'bao': {
                'z': to_gpu(bao_data['z'].values),
                'rd': to_gpu(bao_data['rd'].values),
                'rd_err': to_gpu(bao_data['rd_err'].values),
                'df': bao_data
            }
        }
        return gpu_data
    else:
        # Return standard data when GPU not available
        return {'h0': h0_data, 'sne': sne_data, 'bao': bao_data}
```

## Benchmarking and Profiling:

When moving to GPU-accelerated computation, it's important to benchmark and profile your code to ensure you're getting performance benefits:

1. **Simple Benchmarking**:
```python
def benchmark_likelihood_calculation(use_gpu=True):
    """Benchmark likelihood calculation with CPU vs GPU"""
    params = (3.5, -0.0333)  # Example parameter values
    
    # Load data
    h0_data = load_h0_measurements()
    sne_data = load_supernovae_data()
    bao_data = load_bao_data()
    
    # Time CPU version
    start_cpu = time.time()
    for _ in range(100):  # Run multiple iterations for reliable timing
        log_likelihood(params, h0_data, sne_data, bao_data, 0.02, 0.1)
    cpu_time = (time.time() - start_cpu) / 100
    
    # Time GPU version if available
    if HAS_GPU and use_gpu:
        start_gpu = time.time()
        for _ in range(100):
            log_likelihood_gpu(params, h0_data, sne_data, bao_data, 0.02, 0.1)
        gpu_time = (time.time() - start_gpu) / 100
        
        # Report speedup
        speedup = cpu_time / gpu_time
        print(f"CPU time: {cpu_time:.6f}s, GPU time: {gpu_time:.6f}s")
        print(f"GPU speedup: {speedup:.2f}x")
    else:
        print(f"CPU time: {cpu_time:.6f}s (GPU not available)")
```

2. **Identifying Bottlenecks**:
   - Use the `time_kernel` function to identify which functions benefit most from GPU acceleration:
   ```python
   def time_kernel(func, *args, **kwargs):
       """Time a function execution"""
       start = time.time()
       result = func(*args, **kwargs)
       elapsed = time.time() - start
       print(f"{func.__name__}: {elapsed:.6f}s")
       return result, elapsed
   ```

## CUDA Version Selection:

CuPy needs to match your installed CUDA version. Common installations include:

- `pip install cupy-cuda11x` (for CUDA 11.x)
- `pip install cupy-cuda12x` (for CUDA 12.x)
- `pip install cupy-cuda10x` (for CUDA 10.x)

Check your NVIDIA driver version with `nvidia-smi` to determine the appropriate CUDA version.

## System Configurations for Optimal GPU Performance:

1. **Reserved GPU Memory**: For systems with multiple GPU users, reserve GPU memory:
   ```python
   if HAS_GPU:
       # Limit GPU memory usage to 90% of available memory
       memory_pool = cp.cuda.MemoryPool(cp.cuda.set_allocator)
       cp.cuda.set_allocator(memory_pool.malloc)
       with cp.cuda.Device(0):  # Use GPU device 0
           mempool = cp.get_default_memory_pool()
           mempool.set_limit(fraction=0.9)  # Use up to 90% of GPU memory
   ```

2. **Multi-GPU Support**: For systems with multiple GPUs:
   ```python
   def get_best_gpu():
       """Select the GPU with most available memory"""
       if HAS_GPU:
           n_gpus = cp.cuda.runtime.getDeviceCount()
           free_memory = []
           
           for i in range(n_gpus):
               with cp.cuda.Device(i):
                   meminfo = cp.cuda.runtime.memGetInfo()
                   free_memory.append(meminfo[0])  # Free memory
           
           best_gpu = np.argmax(free_memory)
           print(f"Selected GPU {best_gpu} with {free_memory[best_gpu]/1e9:.2f} GB free memory")
           return best_gpu
       return 0  # Default to first GPU if not available
   
   # Use best GPU
   if HAS_GPU:
       best_gpu = get_best_gpu()
       cp.cuda.Device(best_gpu).use()
   ```

By implementing these additional GPU acceleration techniques, you'll be able to run your MCMC parameter sweep much more efficiently, potentially reducing computation time by an order of magnitude for large datasets.
